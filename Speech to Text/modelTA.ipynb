{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYM1J2zEOIcg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# !pip install datasets==2.6.1\n",
        "!pip install install transformers==4.28\n",
        "# !pip install huggingface_hub\n",
        "!pip install torchaudio\n",
        "# !pip install librosa\n",
        "# !pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install peft==0.2.0"
      ],
      "metadata": {
        "id": "uG_q4xaXONml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "01y6t5oxOPUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "symkrv_lORFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate"
      ],
      "metadata": {
        "id": "XrrmzHvBOSuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bitsandbytes"
      ],
      "metadata": {
        "id": "_6lGMa-dOULX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt_dlp\n",
        "import yt_dlp as youtube_dl"
      ],
      "metadata": {
        "id": "YUyXgxahOVa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import (\n",
        "    AutomaticSpeechRecognitionPipeline,\n",
        "    WhisperForConditionalGeneration,\n",
        "    WhisperTokenizer,\n",
        "    WhisperProcessor,\n",
        ")\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "from transformers.pipelines.audio_utils import ffmpeg_read\n",
        "\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "\n",
        "peft_model_id = \"mfaiq2307/whisper-large-v2-indo-100steps\"\n",
        "language = \"Indonesian\"\n",
        "task = \"transcribe\"\n",
        "peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\n",
        "    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "###coba Onnx\n",
        "#model.eval()\n",
        "#model.get_base_model().save_pretrained(\"./temp_lora_whisper_large_v2_mr\")\n",
        "#from optimum.onnxruntime import ORTModelForSpeechSeq2Seq\n",
        "#\n",
        "#model = ORTModelForSpeechSeq2Seq.from_pretrained(\n",
        "#    \"./temp_lora_whisper_large_v2_mr\", from_transformers=True, provider=\"CUDAExecutionProvider\"\n",
        "#)\n",
        "###coba ONNx\n",
        "tokenizer = WhisperTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
        "processor = WhisperProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
        "feature_extractor = processor.feature_extractor\n",
        "forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=task)\n",
        "pipe = AutomaticSpeechRecognitionPipeline(model=model, tokenizer=tokenizer, feature_extractor=feature_extractor, chunk_length_s=30)\n",
        "\n",
        "\n",
        "def transcribe(audio):\n",
        "    with torch.cuda.amp.autocast():\n",
        "        text = pipe(audio, generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids}, max_new_tokens=255)[\"text\"]\n",
        "    return text\n",
        "\n",
        "def download_yt_audio(yt_url, filename):\n",
        "        info_loader = youtube_dl.YoutubeDL()\n",
        "        try:\n",
        "            info = info_loader.extract_info(yt_url, download=False)\n",
        "        except youtube_dl.utils.DownloadError as err:\n",
        "            raise gr.Error(str(err))\n",
        "        ydl_opts = {\"outtmpl\": filename, \"format\": \"worstvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best\"}\n",
        "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "            try:\n",
        "                ydl.download([yt_url])\n",
        "            except youtube_dl.utils.ExtractorError as err:\n",
        "                raise gr.Error(str(err))\n",
        "\n",
        "def transcribe_youtube(yt_url):\n",
        "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "        filepath = os.path.join(tmpdirname, \"video.mp4\")\n",
        "        download_yt_audio(yt_url, filepath)\n",
        "        with open(filepath, \"rb\") as f:\n",
        "            inputs = f.read()\n",
        "\n",
        "    inputs = ffmpeg_read(inputs, pipe.feature_extractor.sampling_rate)\n",
        "    inputs = {\"array\": inputs, \"sampling_rate\": pipe.feature_extractor.sampling_rate}\n",
        "\n",
        "    with torch.cuda.amp.autocast():\n",
        "        text = pipe(inputs, generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids}, max_new_tokens=255)[\"text\"]\n",
        "\n",
        "    return text\n",
        "\n",
        "audio_file = gr.Interface(\n",
        "    fn=transcribe,\n",
        "    inputs= gr.Audio(source=\"upload\", type=\"filepath\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"PEFT LoRA + INT8 Whisper Large V2 Indo\",\n",
        "    description=\"Realtime demo for Indonesian speech recognition using `PEFT-LoRA+INT8` fine-tuned Whisper Large V2 model.\",\n",
        ")\n",
        "\n",
        "audio_mic = gr.Interface(\n",
        "    fn=transcribe,\n",
        "    inputs= gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"PEFT LoRA + INT8 Whisper Large V2 Indo\",\n",
        "    description=\"Realtime demo for Indonesian speech recognition using `PEFT-LoRA+INT8` fine-tuned Whisper Large V2 model.\",\n",
        ")\n",
        "\n",
        "audio_yt = gr.Interface(\n",
        "    fn=transcribe_youtube,\n",
        "    inputs = gr.inputs.Textbox(lines=1, placeholder=\"Paste the URL to a YouTube video here\", label=\"YouTube URL\"),\n",
        "    #inputs= gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"PEFT LoRA + INT8 Whisper Large V2 Indo\",\n",
        "    description=\"Realtime demo for Indonesian speech recognition using `PEFT-LoRA+INT8` fine-tuned Whisper Large V2 model.\",\n",
        ")\n",
        "\n",
        "demo = gr.Blocks()\n",
        "\n",
        "with demo:\n",
        "    gr.TabbedInterface([audio_file, audio_mic, audio_yt], [\"Audio File\", \"Microphone\", \"Youtube\"])\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "NdP8rNuVOWvT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}